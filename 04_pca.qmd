---
title: "Principal Component Analysis (PCA)"
---

::: {.justify}
Notes: All images displayed on this page are free-use materials, unless otherwise indicated by a specific credit.
:::

# Overview

::: {.justify}
- **Principal Component Analysis (PCA)** is a widely used dimensionality reduction technique in data science and statistics. The main idea of PCA is to transform a set of correlated variables into a smaller set of uncorrelated variables, called principal components, while preserving as much of the original information as possible. Each principal component is a linear combination of the original variables and captures the directions of maximum variance in the dataset.

- At the core of PCA are **eigenvalues** and **eigenvectors**. Eigenvectors define the directions (principal components) along which the data varies the most, while eigenvalues indicate the amount of variance explained by each component. The larger the eigenvalue, the more information the component carries. By ranking components according to their eigenvalues, we can determine how many dimensions should be retained without losing significant information.

- **The significance of dimensionality reduction** lies in **the simplification of analysis and visualization**. By reducing the number of dimensions, patterns and groupings become clearer, and the data can be effectively displayed in two or three dimensions. This allows researchers to intuitively explore relationships, clusters, and structures that would otherwise remain hidden in high-dimensional space.

- **High-dimensional data often poses serious challenges**. It may contain redundancy and noise, and as the number of dimensions increases, the data becomes sparse. This phenomenon is known as the curse of dimensionality, which reduces the reliability of distance calculations, clustering, and nearest-neighbor searches. For example, in low-dimensional space, points may appear relatively close to each other, but in high-dimensional space they tend to be almost equally distant, making it difficult to identify meaningful patterns or similarities. **PCA addresses these issues** by reducing the dimensionality of the dataset while retaining the most important sources of variance. By projecting the data onto fewer principal components, PCA removes redundancy, suppresses noise, and produces a more compact and manageable dataset. This not only improves computational efficiency but also enhances the performance of subsequent machine learning algorithms.
:::

::: {.columns}
::: {.column width="50%"}
![](images/fig_04_overview_01.png){fig-align="center" width="100%"}
:::
::: {.column width="50%"}
![](images/fig_04_overview_02.png){fig-align="center" width="100%"}
:::
:::

# Data Prep

::: {.justify}
- **Principal Component Analysis requires numeric and standardized data**. Since PCA is based on variance and covariance, it can only be applied to numerical variables. If the dataset contains categorical or textual features, they must first be converted into numerical form. For example, categorical variables can be transformed using one-hot encoding, while text data can be vectorized with appropriate methods. Moreover, PCA is sensitive to differences in scale, so it is crucial to normalize or standardize the variables before applying the method. For instance, if one feature is measured in thousands and another in decimals, the feature with the larger scale will dominate the variance and bias the results. Standardization—subtracting the mean and dividing by the standard deviation for each variable—ensures that all features contribute equally to the principal components.
:::

::: {.justify}
- The sample image of the data used in the analysis on this page is shown below. This dataset corresponds to the one shown in "Merged Cleaned Data" at the end of [Data Gathering and Data Cleaning](02_02_data_gathering_and_cleaning.qmd).
:::

::: {.text-center}
![](results/3_PCA/data.jpg){width=100%}
:::

::: {.justify}
- The above dataset can be found [here](https://github.com/taso5789/ds-project-portfolio/tree/main/data/df_merged.csv).
:::

# Code

::: {.justify}
- For the code used in this chapter (Principal Component Analysis (PCA)), please refer [here](https://github.com/taso5789/ds-project-portfolio/blob/main/code/3_PCA.ipynb).
:::

# Results

::: {.justify}
- The results of the principal component analysis (PCA) are discussed and illustrated using the figures.

- @fig-PCA-score shows the explained variance ratio of each principal component as well as the cumulative contribution. The first principal component accounts for about 27% of the total variance, followed by a gradual decline, and the cumulative explained variance reaches roughly 90% with the first ten components. This indicates that while a large portion of the variance can be summarized by a few principal components, multiple components are still needed to capture the overall diversity of the macroeconomic dataset. In particular, the first three components already explain more than half of the total variance, so the focus of interpretation is placed on them.

- @fig-PCA-heatmap shows the relationship between each original macroeconomic variable and the principal components. The first principal component exhibits a strong positive correlation not only with year-over-year (YoY) core inflation rate (`PCEPILFE YoY`) but also with month-over-month (MoM) core inflation rate (`PCEPILFE MoM`). It is also positively correlated with inflation expectations (`T5YIE`, `T10YIE`, `PX_MD`, and `PX_5MD`). In contrast, it shows a negative correlation with the unemployment rate (`UNRATE`), reflecting the Phillips curve trade-off between inflation and unemployment. Thus, the first component can be interpreted as a comprehensive inflation factor, capturing both the medium-term trend (YoY) and short-term fluctuations (MoM).

- The second and third components are more closely related to production and labor market indicators such as industrial production (`INDPRO`), retail sales (`RSAFS`), and average hourly earnings (`CES0500000003`), suggesting that they capture business cycle and labor market dynamics.

- In summary, the scree plot helps identify how many components are necessary to capture the majority of the variance, while the correlation heatmap reveals how the principal components are linked to the original macroeconomic variables. Together, these visualizations make it possible to label the extracted factors in economic terms, such as an inflation factor and business cycle factors. Notably, both year-over-year and month-over-month inflation measures load strongly on the first principal component, indicating that PCA successfully extracts a common factor that encompasses both persistent and short-term inflation dynamics.

![Scree plot of the principal components. The bars indicate the variance explained by each component, while the line shows the cumulative explained variance. The first few components capture the majority of the total variance, after which additional components contribute marginally.](results/3_PCA/pca_scree.png){#fig-PCA-score width=100% fig-align="center"}

![Heatmap of correlations between original macroeconomic variables and the first ten principal components. Red indicates positive correlation, blue indicates negative correlation, and white represents weak or no correlation.](results/3_PCA/pca_corr_heatmap.png){#fig-PCA-heatmap width=100% fig-align="center"}
:::

## Related to Q3 (out of 10 Research Questions) in [Introduction](01_introduction.qmd)

::: {.justify}
**How do macroeconomic factors extracted through principal component analysis (PCA) affect the dynamics of inflation and unemployment?**

- According to @fig-PCA-heatmap, macroeconomic factors extracted through PCA affect the dynamics of inflation and unemployment mainly through two channels:

  1. **Inflation factor (first principal component)**: When this factor rises, both the year-over-year (YoY) and month-over-month (MoM) core inflation rates increase, while the unemployment rate decreases. This reflects a short-run Phillips curve relationship, namely **higher inflationary pressures → lower unemployment**.

  1. **Business cycle factors (second and third principal components)**: These are closely linked to real economic activity (production, retail sales, and labor market indicators) and represent business cycle conditions by primarily driving unemployment fluctuations. Their effects on inflation generally emerge with a lag through the demand channel, with MoM inflation responding earlier than YoY inflation, as it is more sensitive to short-term fluctuations.

- In summary, PCA facilitates the identification of distinct macroeconomic drivers, isolating an inflation factor and business cycle factors, and thereby providing a structured account of how persistent price pressures and cyclical labor market conditions jointly shape the evolution of inflation and unemployment.
:::

# Conclusions

::: {.justify}
- This study applied principal component analysis (PCA) to macroeconomic indicators to identify latent factors shaping inflation and unemployment dynamics. The first principal component emerges as a comprehensive **inflation factor**, strongly correlated with both year-over-year and month-over-month measures of core inflation and inversely related to unemployment, thereby reflecting the Phillips curve trade-off. The second and third components are closely linked to production, retail sales, and labor market indicators, representing **business cycle factors** that primarily drive unemployment fluctuations and indirectly influence inflation.

- Overall, PCA proves effective in reducing the dimensionality of complex datasets while preserving meaningful macroeconomic variation. By distinguishing between inflation and business cycle drivers, PCA provides a structured framework for understanding how persistent price pressures and cyclical labor market conditions jointly shape the economy. These results highlight PCA’s value not only as a statistical tool but also as a means of generating insights relevant for macroeconomic policy analysis.
:::
